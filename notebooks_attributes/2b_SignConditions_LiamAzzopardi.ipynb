{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d0b878b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Filtered 571 -> 571 annotations\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "Validation set:\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Filtered 110 -> 110 annotations\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "Dataset sizes:\n",
      "  Train: 488 images\n",
      "  Val: 93 images\n",
      "\n",
      "Original class distribution (instances):\n",
      "  Good: 369 (64.6%)\n",
      "  Weathered: 172 (30.1%)\n",
      "  Heavily Damaged: 30 (5.3%)\n",
      "\n",
      "Class weights (for sampling):\n",
      "  Good: 0.52\n",
      "  Weathered: 1.11\n",
      "  Heavily Damaged: 6.34\n",
      "\n",
      "Weighted sampler created with 488 samples\n",
      "\n",
      "Steps per epoch:\n",
      "  Train: 122 steps\n",
      "  Val: 24 steps\n",
      "\n",
      "Using device: cuda\n",
      "\n",
      "Starting training for 15 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 [Train]: 100%|██████████| 122/122 [04:30<00:00,  2.21s/it, loss=0.7219]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classes seen in epoch 1:\n",
      "  Good: 184 (32.6%)\n",
      "  Weathered: 182 (32.2%)\n",
      "  Heavily Damaged: 199 (35.2%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 [Val]  : 100%|██████████| 24/24 [00:39<00:00,  1.65s/it, loss=0.7639]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/15:\n",
      "  Train Loss: 0.8389 (cls: 0.6261, bbox: 0.2128)\n",
      "  Val Loss:   0.7700 (cls: 0.5293, bbox: 0.2407)\n",
      "  Overfit Ratio: 1.090\n",
      "  LR: 0.000100\n",
      "New best model saved (improved by inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15 [Train]: 100%|██████████| 122/122 [04:35<00:00,  2.26s/it, loss=0.4243]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classes seen in epoch 2:\n",
      "  Good: 161 (28.6%)\n",
      "  Weathered: 211 (37.5%)\n",
      "  Heavily Damaged: 190 (33.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15 [Val]  : 100%|██████████| 24/24 [00:42<00:00,  1.75s/it, loss=0.7731]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/15:\n",
      "  Train Loss: 0.5629 (cls: 0.3945, bbox: 0.1684)\n",
      "  Val Loss:   0.7049 (cls: 0.4638, bbox: 0.2412)\n",
      "  Overfit Ratio: 0.798\n",
      "  LR: 0.000100\n",
      "New best model saved (improved by 0.0651)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15 [Train]: 100%|██████████| 122/122 [04:45<00:00,  2.34s/it, loss=0.3567]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classes seen in epoch 3:\n",
      "  Good: 210 (36.9%)\n",
      "  Weathered: 206 (36.2%)\n",
      "  Heavily Damaged: 153 (26.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15 [Val]  : 100%|██████████| 24/24 [00:40<00:00,  1.70s/it, loss=0.6725]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/15:\n",
      "  Train Loss: 0.5188 (cls: 0.3572, bbox: 0.1616)\n",
      "  Val Loss:   0.6536 (cls: 0.4122, bbox: 0.2414)\n",
      "  Overfit Ratio: 0.794\n",
      "  LR: 0.000100\n",
      "New best model saved (improved by 0.0513)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15 [Train]: 100%|██████████| 122/122 [04:42<00:00,  2.32s/it, loss=0.6278]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classes seen in epoch 4:\n",
      "  Good: 203 (35.2%)\n",
      "  Weathered: 204 (35.4%)\n",
      "  Heavily Damaged: 170 (29.5%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15 [Val]  : 100%|██████████| 24/24 [00:36<00:00,  1.52s/it, loss=0.6997]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/15:\n",
      "  Train Loss: 0.4758 (cls: 0.3352, bbox: 0.1406)\n",
      "  Val Loss:   0.6430 (cls: 0.4060, bbox: 0.2370)\n",
      "  Overfit Ratio: 0.740\n",
      "  LR: 0.000100\n",
      "New best model saved (improved by 0.0106)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15 [Train]: 100%|██████████| 122/122 [04:28<00:00,  2.20s/it, loss=0.6006]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classes seen in epoch 5:\n",
      "  Good: 192 (34.7%)\n",
      "  Weathered: 195 (35.2%)\n",
      "  Heavily Damaged: 167 (30.1%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15 [Val]  : 100%|██████████| 24/24 [00:36<00:00,  1.50s/it, loss=0.6553]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/15:\n",
      "  Train Loss: 0.4398 (cls: 0.3072, bbox: 0.1327)\n",
      "  Val Loss:   0.6445 (cls: 0.4067, bbox: 0.2378)\n",
      "  Overfit Ratio: 0.682\n",
      "  LR: 0.000100\n",
      "  Patience: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15 [Train]: 100%|██████████| 122/122 [04:23<00:00,  2.16s/it, loss=0.7421]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classes seen in epoch 6:\n",
      "  Good: 205 (36.3%)\n",
      "  Weathered: 158 (28.0%)\n",
      "  Heavily Damaged: 201 (35.6%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15 [Val]  : 100%|██████████| 24/24 [00:35<00:00,  1.49s/it, loss=0.6652]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/15:\n",
      "  Train Loss: 0.4206 (cls: 0.2909, bbox: 0.1297)\n",
      "  Val Loss:   0.6045 (cls: 0.3854, bbox: 0.2191)\n",
      "  Overfit Ratio: 0.696\n",
      "  LR: 0.000100\n",
      "New best model saved (improved by 0.0385)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15 [Train]: 100%|██████████| 122/122 [04:28<00:00,  2.20s/it, loss=0.5275]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classes seen in epoch 7:\n",
      "  Good: 231 (39.2%)\n",
      "  Weathered: 196 (33.3%)\n",
      "  Heavily Damaged: 162 (27.5%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15 [Val]  : 100%|██████████| 24/24 [00:38<00:00,  1.61s/it, loss=0.6764]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/15:\n",
      "  Train Loss: 0.3919 (cls: 0.2694, bbox: 0.1225)\n",
      "  Val Loss:   0.5911 (cls: 0.3652, bbox: 0.2259)\n",
      "  Overfit Ratio: 0.663\n",
      "  LR: 0.000100\n",
      "New best model saved (improved by 0.0134)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15 [Train]: 100%|██████████| 122/122 [04:50<00:00,  2.38s/it, loss=0.1996]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classes seen in epoch 8:\n",
      "  Good: 197 (35.2%)\n",
      "  Weathered: 201 (35.9%)\n",
      "  Heavily Damaged: 162 (28.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15 [Val]  : 100%|██████████| 24/24 [00:40<00:00,  1.69s/it, loss=0.7633]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/15:\n",
      "  Train Loss: 0.3525 (cls: 0.2308, bbox: 0.1217)\n",
      "  Val Loss:   0.6417 (cls: 0.4057, bbox: 0.2360)\n",
      "  Overfit Ratio: 0.549\n",
      "  LR: 0.000100\n",
      "  Patience: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15 [Train]: 100%|██████████| 122/122 [04:51<00:00,  2.39s/it, loss=0.3531]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classes seen in epoch 9:\n",
      "  Good: 214 (37.1%)\n",
      "  Weathered: 189 (32.8%)\n",
      "  Heavily Damaged: 174 (30.2%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15 [Val]  : 100%|██████████| 24/24 [00:37<00:00,  1.58s/it, loss=0.6304]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/15:\n",
      "  Train Loss: 0.3220 (cls: 0.2054, bbox: 0.1166)\n",
      "  Val Loss:   0.6163 (cls: 0.3873, bbox: 0.2290)\n",
      "  Overfit Ratio: 0.522\n",
      "  LR: 0.000100\n",
      "  Patience: 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15 [Train]: 100%|██████████| 122/122 [04:45<00:00,  2.34s/it, loss=0.2554]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classes seen in epoch 10:\n",
      "  Good: 198 (36.3%)\n",
      "  Weathered: 192 (35.2%)\n",
      "  Heavily Damaged: 156 (28.6%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15 [Val]  : 100%|██████████| 24/24 [00:37<00:00,  1.57s/it, loss=0.5390]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/15:\n",
      "  Train Loss: 0.2974 (cls: 0.1890, bbox: 0.1083)\n",
      "  Val Loss:   0.6365 (cls: 0.4052, bbox: 0.2313)\n",
      "  Overfit Ratio: 0.467\n",
      "  LR: 0.000100\n",
      "  Patience: 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15 [Train]: 100%|██████████| 122/122 [04:46<00:00,  2.35s/it, loss=0.1381]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classes seen in epoch 11:\n",
      "  Good: 205 (36.3%)\n",
      "  Weathered: 185 (32.7%)\n",
      "  Heavily Damaged: 175 (31.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15 [Val]  : 100%|██████████| 24/24 [00:38<00:00,  1.59s/it, loss=0.4962]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11/15:\n",
      "  Train Loss: 0.2737 (cls: 0.1785, bbox: 0.0952)\n",
      "  Val Loss:   0.5933 (cls: 0.3659, bbox: 0.2274)\n",
      "  Overfit Ratio: 0.461\n",
      "  LR: 0.000050\n",
      "  Patience: 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15 [Train]: 100%|██████████| 122/122 [04:39<00:00,  2.29s/it, loss=0.1641]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classes seen in epoch 12:\n",
      "  Good: 203 (35.9%)\n",
      "  Weathered: 195 (34.5%)\n",
      "  Heavily Damaged: 167 (29.6%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15 [Val]  : 100%|██████████| 24/24 [00:39<00:00,  1.66s/it, loss=0.5655]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12/15:\n",
      "  Train Loss: 0.2135 (cls: 0.1325, bbox: 0.0810)\n",
      "  Val Loss:   0.6049 (cls: 0.3931, bbox: 0.2118)\n",
      "  Overfit Ratio: 0.353\n",
      "  LR: 0.000050\n",
      "  Patience: 5/5\n",
      "\n",
      "Early stopping triggered at epoch 12\n",
      "Best validation loss: 0.5911\n",
      "Stopped at epoch: 12\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import retinanet_resnet50_fpn\n",
    "from torchvision.models.detection import RetinaNet_ResNet50_FPN_Weights\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from torchvision.datasets import CocoDetection\n",
    "import torchvision.transforms as T\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#RETINANET for sign conditions\n",
    "\n",
    "train_json = r'COCO-based_COCO_condition\\annotations\\train.json'\n",
    "val_json = r'COCO-based_COCO_condition\\annotations\\val.json'\n",
    "train_img_dir = r'COCO-based_COCO_condition\\images\\train'\n",
    "val_img_dir = r'COCO-based_COCO_condition\\images\\val'\n",
    "\n",
    "# conditions\n",
    "allowed_conditions = [\"Good\", \"Weathered\", \"Heavily Damaged\"]\n",
    "\n",
    "# Number of classes: 3 conditions + 1 background = 4\n",
    "num_classes = 4\n",
    "\n",
    "# parameters\n",
    "BATCH_SIZE = 4\n",
    "NUM_EPOCHS = 15\n",
    "LEARNING_RATE = 0.0001\n",
    "NUM_WORKERS = 0  \n",
    "\n",
    "# Early stopping\n",
    "PATIENCE = 5\n",
    "\n",
    "# TensorBoard configuration\n",
    "EXPERIMENT_NAME = f\"retinanet_balanced_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "LOG_DIR = os.path.join('runs', EXPERIMENT_NAME)\n",
    "\n",
    "\n",
    "class FilteredCocoDetection(CocoDetection):\n",
    "    def __init__(self, root, annFile, allowed_conditions):\n",
    "        super().__init__(root, annFile)\n",
    "        self.annFile = annFile\n",
    "        self.allowed_conditions = allowed_conditions\n",
    "        self._filter_annotations()\n",
    "    \n",
    "    def _filter_annotations(self):\n",
    "        \"\"\"Filter annotations to only include allowed conditions\"\"\"\n",
    "        with open(self.annFile, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        filtered_anns = []\n",
    "        for ann in data['annotations']:\n",
    "            if 'attributes' in ann and 'condition' in ann['attributes']:\n",
    "                condition = ann['attributes']['condition'][0]\n",
    "                if condition in self.allowed_conditions:\n",
    "                    ann['category_id'] = self.allowed_conditions.index(condition) + 1\n",
    "                    filtered_anns.append(ann)\n",
    "        \n",
    "        print(f\"Filtered {len(data['annotations'])} -> {len(filtered_anns)} annotations\")\n",
    "        \n",
    "        data['annotations'] = filtered_anns\n",
    "        data['categories'] = [\n",
    "            {'id': i+1, 'name': cond} \n",
    "            for i, cond in enumerate(self.allowed_conditions)\n",
    "        ]\n",
    "        \n",
    "        self.coco.dataset = data\n",
    "        self.coco.createIndex()\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Override to return proper format for RetinaNet\"\"\"\n",
    "        img, target = super().__getitem__(idx)\n",
    "        \n",
    "        # Convert image to tensor\n",
    "        img = T.ToTensor()(img)\n",
    "        \n",
    "        # Convert target to proper format\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        \n",
    "        for obj in target:\n",
    "            if 'bbox' in obj and 'category_id' in obj:\n",
    "                x, y, w, h = obj['bbox']\n",
    "                boxes.append([x, y, x + w, y + h])\n",
    "                labels.append(obj['category_id'])\n",
    "        \n",
    "        if len(boxes) == 0:\n",
    "            boxes = torch.zeros((0, 4), dtype=torch.float32)\n",
    "            labels = torch.zeros((0,), dtype=torch.int64)\n",
    "        else:\n",
    "            boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "            labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        \n",
    "        target_dict = {\n",
    "            'boxes': boxes,\n",
    "            'labels': labels\n",
    "        }\n",
    "        \n",
    "        return img, target_dict\n",
    "\n",
    "\n",
    "model = retinanet_resnet50_fpn(weights=RetinaNet_ResNet50_FPN_Weights.DEFAULT)\n",
    "\n",
    "# Modify classification head for your number of classes\n",
    "in_features = 256\n",
    "num_anchors = model.head.classification_head.num_anchors\n",
    "\n",
    "from torchvision.models.detection.retinanet import RetinaNetClassificationHead\n",
    "model.head.classification_head = RetinaNetClassificationHead(\n",
    "    in_channels=in_features,\n",
    "    num_anchors=num_anchors,\n",
    "    num_classes=num_classes\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Training set:\")\n",
    "train_dataset = FilteredCocoDetection(\n",
    "    root=train_img_dir, \n",
    "    annFile=train_json, \n",
    "    allowed_conditions=allowed_conditions\n",
    ")\n",
    "\n",
    "print(\"\\nValidation set:\")\n",
    "val_dataset = FilteredCocoDetection(\n",
    "    root=val_img_dir, \n",
    "    annFile=val_json, \n",
    "    allowed_conditions=allowed_conditions\n",
    ")\n",
    "\n",
    "print(f\"\\nDataset sizes:\")\n",
    "print(f\"  Train: {len(train_dataset)} images\")\n",
    "print(f\"  Val: {len(val_dataset)} images\")\n",
    "\n",
    "\n",
    "# Count instances per class and track each sample's classes\n",
    "class_instance_count = defaultdict(int)\n",
    "sample_labels = []\n",
    "\n",
    "for idx in range(len(train_dataset)):\n",
    "    _, target = train_dataset[idx]\n",
    "    labels = target['labels'].tolist()\n",
    "    \n",
    "    if labels:\n",
    "        sample_labels.append(labels)\n",
    "        for label in labels:\n",
    "            class_instance_count[label] += 1\n",
    "    else:\n",
    "        sample_labels.append([1])  # Default to class 1 if no labels\n",
    "\n",
    "print(\"\\nOriginal class distribution (instances):\")\n",
    "for cls in sorted(class_instance_count.keys()):\n",
    "    count = class_instance_count[cls]\n",
    "    pct = 100 * count / sum(class_instance_count.values())\n",
    "    print(f\"  {allowed_conditions[cls-1]}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "# Calculate class weights (inverse frequency)\n",
    "total_instances = sum(class_instance_count.values())\n",
    "class_weights = {}\n",
    "for cls, count in class_instance_count.items():\n",
    "    # Weight is inversely proportional to frequency\n",
    "    # Add smoothing to avoid extreme weights\n",
    "    class_weights[cls] = total_instances / (count * len(class_instance_count))\n",
    "\n",
    "print(\"\\nClass weights (for sampling):\")\n",
    "for cls in sorted(class_weights.keys()):\n",
    "    print(f\"  {allowed_conditions[cls-1]}: {class_weights[cls]:.2f}\")\n",
    "\n",
    "# Assign weight to each sample based on rarest class present\n",
    "sample_weights = []\n",
    "for labels in sample_labels:\n",
    "    # Weight by the rarest class in the image\n",
    "    weights = [class_weights[label] for label in labels]\n",
    "    sample_weights.append(max(weights))\n",
    "\n",
    "# Create weighted random sampler\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights,\n",
    "    num_samples=len(sample_weights),\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "print(f\"\\nWeighted sampler created with {len(sample_weights)} samples\")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    sampler=sampler,  \n",
    "    num_workers=NUM_WORKERS, \n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    num_workers=NUM_WORKERS, \n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "print(f\"\\nSteps per epoch:\")\n",
    "print(f\"  Train: {len(train_loader)} steps\")\n",
    "print(f\"  Val: {len(val_loader)} steps\")\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nUsing device: {device}\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.AdamW(params, lr=LEARNING_RATE, weight_decay=0.0001)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=3\n",
    ")\n",
    "\n",
    "\n",
    "writer = SummaryWriter(log_dir=LOG_DIR)\n",
    "\n",
    "writer.add_text('Hyperparameters', f'''\n",
    "- Batch Size: {BATCH_SIZE}\n",
    "- Learning Rate: {LEARNING_RATE}\n",
    "- Weight Decay: 0.0005\n",
    "- Optimizer: AdamW\n",
    "- Scheduler: ReduceLROnPlateau (patience=5, factor=0.5)\n",
    "- Number of Classes: {num_classes}\n",
    "- Conditions: {\", \".join(allowed_conditions)}\n",
    "- Train Images: {len(train_dataset)}\n",
    "- Val Images: {len(val_dataset)}\n",
    "- **BALANCED SAMPLING ENABLED**\n",
    "- Class Weights: Good={class_weights[1]:.2f}, Weathered={class_weights[2]:.2f}, Heavily Damaged={class_weights[3]:.2f}\n",
    "''')\n",
    "\n",
    "\n",
    "#tensorboard --logdir=runs\n",
    "\n",
    "\n",
    "print(f\"\\nStarting training for {NUM_EPOCHS} epochs\")\n",
    "\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "global_step = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_cls_loss = 0\n",
    "    train_box_loss = 0\n",
    "    \n",
    "    # Track which classes appear in batches\n",
    "    epoch_class_counts = defaultdict(int)\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{NUM_EPOCHS} [Train]')\n",
    "    for batch_idx, (images, targets) in enumerate(pbar):\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        \n",
    "        # Track class distribution in this batch\n",
    "        for target in targets:\n",
    "            for label in target['labels']:\n",
    "                epoch_class_counts[label.item()] += 1\n",
    "        \n",
    "        # Skip empty batches\n",
    "        if any(len(t['boxes']) == 0 for t in targets):\n",
    "            continue\n",
    "        \n",
    "        # Forward pass\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        \n",
    "        cls_loss = loss_dict.get('classification', torch.tensor(0.0))\n",
    "        box_loss = loss_dict.get('bbox_regression', torch.tensor(0.0))\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += losses.item()\n",
    "        train_cls_loss += cls_loss.item()\n",
    "        train_box_loss += box_loss.item()\n",
    "        \n",
    "        # Log to TensorBoard\n",
    "        writer.add_scalar('Train/Batch_Loss', losses.item(), global_step)\n",
    "        writer.add_scalar('Train/Batch_Classification_Loss', cls_loss.item(), global_step)\n",
    "        writer.add_scalar('Train/Batch_BBox_Loss', box_loss.item(), global_step)\n",
    "        \n",
    "        global_step += 1\n",
    "        pbar.set_postfix({'loss': f'{losses.item():.4f}'})\n",
    "    \n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    train_cls_loss = train_cls_loss / len(train_loader)\n",
    "    train_box_loss = train_box_loss / len(train_loader)\n",
    "    \n",
    "    # Log class distribution seen during training\n",
    "    print(f\"\\nClasses seen in epoch {epoch+1}:\")\n",
    "    total_seen = sum(epoch_class_counts.values())\n",
    "    for cls in sorted(epoch_class_counts.keys()):\n",
    "        count = epoch_class_counts[cls]\n",
    "        pct = 100 * count / total_seen if total_seen > 0 else 0\n",
    "        print(f\"  {allowed_conditions[cls-1]}: {count} ({pct:.1f}%)\")\n",
    "        writer.add_scalar(f'Training_Distribution/{allowed_conditions[cls-1]}', count, epoch)\n",
    "    \n",
    "   \n",
    "    model.train()\n",
    "    val_loss = 0\n",
    "    val_cls_loss = 0\n",
    "    val_box_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{NUM_EPOCHS} [Val]  ')\n",
    "        for images, targets in pbar:\n",
    "            images = [img.to(device) for img in images]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            \n",
    "            if any(len(t['boxes']) == 0 for t in targets):\n",
    "                continue\n",
    "            \n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            \n",
    "            cls_loss = loss_dict.get('classification', torch.tensor(0.0))\n",
    "            box_loss = loss_dict.get('bbox_regression', torch.tensor(0.0))\n",
    "            \n",
    "            val_loss += losses.item()\n",
    "            val_cls_loss += cls_loss.item()\n",
    "            val_box_loss += box_loss.item()\n",
    "            \n",
    "            pbar.set_postfix({'loss': f'{losses.item():.4f}'})\n",
    "    \n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    val_cls_loss = val_cls_loss / len(val_loader)\n",
    "    val_box_loss = val_box_loss / len(val_loader)\n",
    "    \n",
    "    # Update scheduler\n",
    "    scheduler.step(val_loss)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "\n",
    "    \n",
    "    writer.add_scalars('Loss/Total', {'train': train_loss, 'val': val_loss}, epoch)\n",
    "    writer.add_scalars('Loss/Classification', {'train': train_cls_loss, 'val': val_cls_loss}, epoch)\n",
    "    writer.add_scalars('Loss/BBox_Regression', {'train': train_box_loss, 'val': val_box_loss}, epoch)\n",
    "    \n",
    "    overfit_ratio = train_loss / val_loss if val_loss > 0 else 1.0\n",
    "    writer.add_scalar('Metrics/Overfit_Ratio', overfit_ratio, epoch)\n",
    "    writer.add_scalar('Hyperparameters/Learning_Rate', current_lr, epoch)\n",
    "    \n",
    "   \n",
    "    print(f'\\nEpoch {epoch+1}/{NUM_EPOCHS}:')\n",
    "    print(f'  Train Loss: {train_loss:.4f} (cls: {train_cls_loss:.4f}, bbox: {train_box_loss:.4f})')\n",
    "    print(f'  Val Loss:   {val_loss:.4f} (cls: {val_cls_loss:.4f}, bbox: {val_box_loss:.4f})')\n",
    "    print(f'  Overfit Ratio: {overfit_ratio:.3f}')\n",
    "    print(f'  LR: {current_lr:.6f}')\n",
    "    \n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        improvement = best_val_loss - val_loss\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        \n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'class_weights': class_weights,\n",
    "        }, 'retinanet_best.pth')\n",
    "        \n",
    "        print(f'New best model saved (improved by {improvement:.4f})')\n",
    "        writer.add_scalar('Metrics/Best_Val_Loss', best_val_loss, epoch)\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f'  Patience: {patience_counter}/{PATIENCE}')\n",
    "        \n",
    "        if patience_counter >= PATIENCE:\n",
    "            print(f'\\nEarly stopping triggered at epoch {epoch+1}')\n",
    "            break\n",
    "    \n",
    "    # Save last model\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'class_weights': class_weights,\n",
    "    }, 'retinanet_last.pth')\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "print(f\"Stopped at epoch: {epoch+1}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94e4169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import retinanet_resnet50_fpn\n",
    "from torchvision.models.detection import RetinaNet_ResNet50_FPN_Weights\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CocoDetection\n",
    "import torchvision.transforms as T\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from pycocotools.coco import COCO\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "test_json = r'COCO-based_COCO_condition\\annotations\\test.json'\n",
    "test_img_dir = r'COCO-based_COCO_condition\\images\\test'\n",
    "\n",
    "\n",
    "allowed_conditions = [\"Good\", \"Weathered\", \"Heavily Damaged\"]\n",
    "num_classes = 4\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "# Model checkpoint to evaluate\n",
    "MODEL_PATH = 'retinanet_best.pth'  \n",
    "\n",
    "#threshold\n",
    "CONFIDENCE_THRESHOLD = 0.5\n",
    "\n",
    "\n",
    "\n",
    "class FilteredCocoDetection(CocoDetection):\n",
    "    def __init__(self, root, annFile, allowed_conditions):\n",
    "        super().__init__(root, annFile)\n",
    "        self.annFile = annFile\n",
    "        self.allowed_conditions = allowed_conditions\n",
    "        self._filter_annotations()\n",
    "    \n",
    "    def _filter_annotations(self):\n",
    "        \"\"\"Filter annotations to only include allowed conditions\"\"\"\n",
    "        with open(self.annFile, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        filtered_anns = []\n",
    "        for ann in data['annotations']:\n",
    "            if 'attributes' in ann and 'condition' in ann['attributes']:\n",
    "                condition = ann['attributes']['condition'][0]\n",
    "                if condition in self.allowed_conditions:\n",
    "                    ann['category_id'] = self.allowed_conditions.index(condition) + 1\n",
    "                    filtered_anns.append(ann)\n",
    "        \n",
    "        print(f\"Filtered {len(data['annotations'])} -> {len(filtered_anns)} annotations\")\n",
    "        \n",
    "        data['annotations'] = filtered_anns\n",
    "        data['categories'] = [\n",
    "            {'id': i+1, 'name': cond} \n",
    "            for i, cond in enumerate(self.allowed_conditions)\n",
    "        ]\n",
    "        \n",
    "        self.coco.dataset = data\n",
    "        self.coco.createIndex()\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Override to return proper format for RetinaNet\"\"\"\n",
    "        img, target = super().__getitem__(idx)\n",
    "        img_id = self.ids[idx]\n",
    "        \n",
    "        # Convert image to tensor\n",
    "        img_tensor = T.ToTensor()(img)\n",
    "        \n",
    "        # Convert target to proper format\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        \n",
    "        for obj in target:\n",
    "            if 'bbox' in obj and 'category_id' in obj:\n",
    "                x, y, w, h = obj['bbox']\n",
    "                boxes.append([x, y, x + w, y + h])\n",
    "                labels.append(obj['category_id'])\n",
    "        \n",
    "        if len(boxes) == 0:\n",
    "            boxes = torch.zeros((0, 4), dtype=torch.float32)\n",
    "            labels = torch.zeros((0,), dtype=torch.int64)\n",
    "        else:\n",
    "            boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "            labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        \n",
    "        target_dict = {\n",
    "            'boxes': boxes,\n",
    "            'labels': labels,\n",
    "            'image_id': torch.tensor([img_id])\n",
    "        }\n",
    "        \n",
    "        return img_tensor, target_dict, img  # Return original PIL image too\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = retinanet_resnet50_fpn(weights=None)\n",
    "\n",
    "# Modify classification head\n",
    "in_features = 256\n",
    "num_anchors = model.head.classification_head.num_anchors\n",
    "\n",
    "from torchvision.models.detection.retinanet import RetinaNetClassificationHead\n",
    "model.head.classification_head = RetinaNetClassificationHead(\n",
    "    in_channels=in_features,\n",
    "    num_anchors=num_anchors,\n",
    "    num_classes=num_classes\n",
    ")\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(MODEL_PATH, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Loaded model from {MODEL_PATH}\")\n",
    "print(f\"  Epoch: {checkpoint['epoch']}\")\n",
    "print(f\"  Val Loss: {checkpoint['val_loss']:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nCreating test dataset...\")\n",
    "test_dataset = FilteredCocoDetection(\n",
    "    root=test_img_dir,\n",
    "    annFile=test_json,\n",
    "    allowed_conditions=allowed_conditions\n",
    ")\n",
    "\n",
    "print(f\"Test set: {len(test_dataset)} images\")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images = [item[0] for item in batch]\n",
    "    targets = [item[1] for item in batch]\n",
    "    orig_images = [item[2] for item in batch]\n",
    "    return images, targets, orig_images\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"Calculate IoU between two boxes [x1, y1, x2, y2]\"\"\"\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "    \n",
    "    intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    union = area1 + area2 - intersection\n",
    "    \n",
    "    return intersection / union if union > 0 else 0\n",
    "\n",
    "def match_predictions_to_targets(pred_boxes, pred_labels, pred_scores, \n",
    "                                  target_boxes, target_labels, iou_threshold=0.5):\n",
    "    \"\"\"Match predictions to ground truth boxes\"\"\"\n",
    "    matches = []\n",
    "    used_targets = set()\n",
    "    \n",
    "    # Sort predictions by score (highest first)\n",
    "    sorted_indices = torch.argsort(pred_scores, descending=True)\n",
    "    \n",
    "    for idx in sorted_indices:\n",
    "        pred_box = pred_boxes[idx].cpu().numpy()\n",
    "        pred_label = pred_labels[idx].item()\n",
    "        pred_score = pred_scores[idx].item()\n",
    "        \n",
    "        best_iou = 0\n",
    "        best_target_idx = -1\n",
    "        \n",
    "        for t_idx, (target_box, target_label) in enumerate(zip(target_boxes, target_labels)):\n",
    "            if t_idx in used_targets:\n",
    "                continue\n",
    "            \n",
    "            target_box = target_box.cpu().numpy()\n",
    "            target_label = target_label.item()\n",
    "            \n",
    "            if pred_label != target_label:\n",
    "                continue\n",
    "            \n",
    "            iou = calculate_iou(pred_box, target_box)\n",
    "            \n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                best_target_idx = t_idx\n",
    "        \n",
    "        if best_iou >= iou_threshold:\n",
    "            matches.append({\n",
    "                'pred_idx': idx.item(),\n",
    "                'target_idx': best_target_idx,\n",
    "                'iou': best_iou,\n",
    "                'label': pred_label,\n",
    "                'score': pred_score,\n",
    "                'correct': True\n",
    "            })\n",
    "            used_targets.add(best_target_idx)\n",
    "        else:\n",
    "            matches.append({\n",
    "                'pred_idx': idx.item(),\n",
    "                'target_idx': -1,\n",
    "                'iou': best_iou,\n",
    "                'label': pred_label,\n",
    "                'score': pred_score,\n",
    "                'correct': False\n",
    "            })\n",
    "    \n",
    "    return matches\n",
    "\n",
    "\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "per_class_stats = defaultdict(lambda: {'tp': 0, 'fp': 0, 'fn': 0, 'ious': []})\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, targets, orig_images in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "        images = [img.to(device) for img in images]\n",
    "        \n",
    "        # Get predictions\n",
    "        predictions = model(images)\n",
    "        \n",
    "        # Process each image in batch\n",
    "        for pred, target in zip(predictions, targets):\n",
    "            # Filter by confidence threshold\n",
    "            keep = pred['scores'] > CONFIDENCE_THRESHOLD\n",
    "            pred_boxes = pred['boxes'][keep]\n",
    "            pred_labels = pred['labels'][keep]\n",
    "            pred_scores = pred['scores'][keep]\n",
    "            \n",
    "            target_boxes = target['boxes']\n",
    "            target_labels = target['labels']\n",
    "            \n",
    "            # Match predictions to targets\n",
    "            matches = match_predictions_to_targets(\n",
    "                pred_boxes, pred_labels, pred_scores,\n",
    "                target_boxes, target_labels\n",
    "            )\n",
    "            \n",
    "            # Store for overall metrics\n",
    "            all_predictions.append({\n",
    "                'boxes': pred_boxes.cpu(),\n",
    "                'labels': pred_labels.cpu(),\n",
    "                'scores': pred_scores.cpu(),\n",
    "                'image_id': target['image_id'].item()\n",
    "            })\n",
    "            \n",
    "            all_targets.append({\n",
    "                'boxes': target_boxes.cpu(),\n",
    "                'labels': target_labels.cpu(),\n",
    "                'image_id': target['image_id'].item()\n",
    "            })\n",
    "            \n",
    "            # Update per-class statistics\n",
    "            for match in matches:\n",
    "                label = match['label']\n",
    "                if match['correct']:\n",
    "                    per_class_stats[label]['tp'] += 1\n",
    "                    per_class_stats[label]['ious'].append(match['iou'])\n",
    "                else:\n",
    "                    per_class_stats[label]['fp'] += 1\n",
    "            \n",
    "            # Count false negatives (unmatched targets)\n",
    "            matched_targets = {m['target_idx'] for m in matches if m['correct']}\n",
    "            for t_idx, label in enumerate(target_labels):\n",
    "                if t_idx not in matched_targets:\n",
    "                    per_class_stats[label.item()]['fn'] += 1\n",
    "\n",
    "\n",
    "\n",
    "print(\"EVALUATION RESULTS\")\n",
    "\n",
    "# Overall statistics\n",
    "total_tp = sum(stats['tp'] for stats in per_class_stats.values())\n",
    "total_fp = sum(stats['fp'] for stats in per_class_stats.values())\n",
    "total_fn = sum(stats['fn'] for stats in per_class_stats.values())\n",
    "\n",
    "overall_precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0\n",
    "overall_recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0\n",
    "overall_f1 = 2 * (overall_precision * overall_recall) / (overall_precision + overall_recall) if (overall_precision + overall_recall) > 0 else 0\n",
    "\n",
    "print(f\"\\nOverall Metrics (IoU threshold = 0.5):\")\n",
    "print(f\"  Precision: {overall_precision:.4f}\")\n",
    "print(f\"  Recall:    {overall_recall:.4f}\")\n",
    "print(f\"  F1-Score:  {overall_f1:.4f}\")\n",
    "\n",
    "# Per-class metrics\n",
    "print(f\"\\nPer-Class Metrics:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "class_metrics = []\n",
    "for class_id in sorted(per_class_stats.keys()):\n",
    "    stats = per_class_stats[class_id]\n",
    "    class_name = allowed_conditions[class_id - 1]\n",
    "    \n",
    "    precision = stats['tp'] / (stats['tp'] + stats['fp']) if (stats['tp'] + stats['fp']) > 0 else 0\n",
    "    recall = stats['tp'] / (stats['tp'] + stats['fn']) if (stats['tp'] + stats['fn']) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    avg_iou = np.mean(stats['ious']) if stats['ious'] else 0\n",
    "    \n",
    "    print(f\"{class_name}:\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall:    {recall:.4f}\")\n",
    "    print(f\"  F1-Score:  {f1:.4f}\")\n",
    "    print(f\"  Avg IoU:   {avg_iou:.4f}\")\n",
    "    print(f\"  TP: {stats['tp']}, FP: {stats['fp']}, FN: {stats['fn']}\")\n",
    "    print()\n",
    "    \n",
    "    class_metrics.append({\n",
    "        'class': class_name,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'avg_iou': avg_iou\n",
    "    })\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "\n",
    "\n",
    "# Initialize confusion matrix\n",
    "conf_matrix = np.zeros((num_classes-1, num_classes-1), dtype=int)\n",
    "\n",
    "for pred, target in zip(all_predictions, all_targets):\n",
    "    pred_labels = pred['labels'].numpy()\n",
    "    target_labels = target['labels'].numpy()\n",
    "    pred_boxes = pred['boxes'].numpy()\n",
    "    target_boxes = target['boxes'].numpy()\n",
    "    \n",
    "    # Match predictions to targets\n",
    "    for target_idx, target_label in enumerate(target_labels):\n",
    "        target_box = target_boxes[target_idx]\n",
    "        best_iou = 0\n",
    "        best_pred_label = None\n",
    "        \n",
    "        for pred_idx, pred_label in enumerate(pred_labels):\n",
    "            pred_box = pred_boxes[pred_idx]\n",
    "            iou = calculate_iou(pred_box, target_box)\n",
    "            \n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                best_pred_label = pred_label\n",
    "        \n",
    "        if best_iou >= 0.5 and best_pred_label is not None:\n",
    "            conf_matrix[target_label-1, best_pred_label-1] += 1\n",
    "        else:\n",
    "            # Missed detection - could add to confusion matrix or track separately\n",
    "            pass\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=allowed_conditions,\n",
    "            yticklabels=allowed_conditions)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix (IoU > 0.5)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=150)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for class_id, class_name in enumerate(allowed_conditions, start=1):\n",
    "    # Collect all predictions and ground truths for this class\n",
    "    class_preds = []\n",
    "    class_targets_count = 0\n",
    "    \n",
    "    for pred, target in zip(all_predictions, all_targets):\n",
    "        # Count ground truth boxes\n",
    "        class_targets_count += (target['labels'] == class_id).sum().item()\n",
    "        \n",
    "        # Get predictions for this class\n",
    "        class_mask = pred['labels'] == class_id\n",
    "        if class_mask.sum() > 0:\n",
    "            scores = pred['scores'][class_mask].numpy()\n",
    "            boxes = pred['boxes'][class_mask].numpy()\n",
    "            \n",
    "            # Check if predictions match ground truth\n",
    "            for score, box in zip(scores, boxes):\n",
    "                is_correct = False\n",
    "                for target_box, target_label in zip(target['boxes'], target['labels']):\n",
    "                    if target_label.item() == class_id:\n",
    "                        iou = calculate_iou(box, target_box.numpy())\n",
    "                        if iou >= 0.5:\n",
    "                            is_correct = True\n",
    "                            break\n",
    "                \n",
    "                class_preds.append({'score': score, 'correct': is_correct})\n",
    "    \n",
    "    # Sort by score\n",
    "    class_preds.sort(key=lambda x: x['score'], reverse=True)\n",
    "    \n",
    "    # Calculate precision and recall at different thresholds\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    \n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    \n",
    "    for pred in class_preds:\n",
    "        if pred['correct']:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "        \n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / class_targets_count if class_targets_count > 0 else 0\n",
    "        \n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "    \n",
    "    # Plot\n",
    "    ax = axes[class_id - 1]\n",
    "    ax.plot(recalls, precisions, linewidth=2)\n",
    "    ax.set_xlabel('Recall')\n",
    "    ax.set_ylabel('Precision')\n",
    "    ax.set_title(f'P-R Curve: {class_name}')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_xlim([0, 1])\n",
    "    ax.set_ylim([0, 1])\n",
    "    \n",
    "    # Calculate AP (area under curve)\n",
    "    ap = np.trapz(precisions, recalls) if recalls else 0\n",
    "    ax.text(0.5, 0.05, f'AP = {ap:.3f}', transform=ax.transAxes, \n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('precision_recall_curves.png', dpi=150)\n",
    "\n",
    "def visualize_predictions(image, pred, target, idx):\n",
    "    \"\"\"Visualize predictions vs ground truth\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # Convert tensor to numpy\n",
    "    if isinstance(image, torch.Tensor):\n",
    "        image = image.permute(1, 2, 0).cpu().numpy()\n",
    "    else:\n",
    "        image = np.array(image)\n",
    "    \n",
    "    # Ground truth\n",
    "    ax1.imshow(image)\n",
    "    ax1.set_title('Ground Truth', fontsize=14, fontweight='bold')\n",
    "    for box, label in zip(target['boxes'], target['labels']):\n",
    "        box = box.cpu().numpy()\n",
    "        x1, y1, x2, y2 = box\n",
    "        rect = patches.Rectangle((x1, y1), x2-x1, y2-y1, \n",
    "                                  linewidth=2, edgecolor='green', facecolor='none')\n",
    "        ax1.add_patch(rect)\n",
    "        ax1.text(x1, y1-5, allowed_conditions[label-1], \n",
    "                 color='white', fontsize=10, \n",
    "                 bbox=dict(boxstyle='round', facecolor='green', alpha=0.7))\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # Predictions\n",
    "    ax2.imshow(image)\n",
    "    ax2.set_title('Predictions', fontsize=14, fontweight='bold')\n",
    "    keep = pred['scores'] > CONFIDENCE_THRESHOLD\n",
    "    for box, label, score in zip(pred['boxes'][keep], pred['labels'][keep], pred['scores'][keep]):\n",
    "        box = box.cpu().numpy()\n",
    "        x1, y1, x2, y2 = box\n",
    "        rect = patches.Rectangle((x1, y1), x2-x1, y2-y1, \n",
    "                                  linewidth=2, edgecolor='red', facecolor='none')\n",
    "        ax2.add_patch(rect)\n",
    "        ax2.text(x1, y1-5, f\"{allowed_conditions[label-1]} ({score:.2f})\", \n",
    "                 color='white', fontsize=10,\n",
    "                 bbox=dict(boxstyle='round', facecolor='red', alpha=0.7))\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'prediction_sample_{idx}.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Visualize first 5 images\n",
    "print(\"Saving visualization of first 5 test images...\")\n",
    "with torch.no_grad():\n",
    "    for idx, (images, targets, orig_images) in enumerate(test_loader):\n",
    "        if idx >= 5:  # Only visualize first 5 batches\n",
    "            break\n",
    "        \n",
    "        images_gpu = [img.to(device) for img in images]\n",
    "        predictions = model(images_gpu)\n",
    "        \n",
    "        for i, (pred, target, orig_img) in enumerate(zip(predictions, targets, orig_images)):\n",
    "            visualize_predictions(orig_img, pred, target, idx * BATCH_SIZE + i)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"EVALUATION SUMMARY\")\n",
    "print(f\"Model: {MODEL_PATH}\")\n",
    "print(f\"Test images: {len(test_dataset)}\")\n",
    "print(f\"Confidence threshold: {CONFIDENCE_THRESHOLD}\")\n",
    "print(f\"\\nOverall Performance:\")\n",
    "print(f\"  Precision: {overall_precision:.4f}\")\n",
    "print(f\"  Recall:    {overall_recall:.4f}\")\n",
    "print(f\"  F1-Score:  {overall_f1:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ARI3129",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
